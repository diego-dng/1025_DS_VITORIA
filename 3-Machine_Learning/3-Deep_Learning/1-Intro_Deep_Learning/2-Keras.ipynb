{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][0][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego Nuñez\\AppData\\Local\\Temp\\ipykernel_5528\\3096108358.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.uint8(255)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(1.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.13066062)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Diego Nuñez\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Dense name=dense, built=True>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04167309,  0.02762947, -0.0305313 , ...,  0.02298317,\n",
       "        -0.02567366, -0.0301808 ],\n",
       "       [-0.02905608,  0.00198039,  0.00922161, ...,  0.07099922,\n",
       "         0.05687451,  0.059724  ],\n",
       "       [-0.01066832,  0.03208178,  0.03796238, ...,  0.03737918,\n",
       "         0.05239019,  0.00095263],\n",
       "       ...,\n",
       "       [-0.03482436,  0.04751902,  0.00221182, ...,  0.06304576,\n",
       "        -0.07343721, -0.0444379 ],\n",
       "       [-0.05527527,  0.04717418, -0.00566888, ..., -0.01264149,\n",
       "         0.06564033,  0.02681676],\n",
       "       [-0.06419904, -0.03146988,  0.04695822, ...,  0.00138009,\n",
       "         0.02065596,  0.00665572]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biases)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Diego Nuñez\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4819 - loss: 1.7535 - val_accuracy: 0.8616 - val_loss: 0.6017\n",
      "Epoch 2/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8562 - loss: 0.5706 - val_accuracy: 0.8964 - val_loss: 0.3968\n",
      "Epoch 3/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8860 - loss: 0.4192 - val_accuracy: 0.9093 - val_loss: 0.3367\n",
      "Epoch 4/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9013 - loss: 0.3595 - val_accuracy: 0.9150 - val_loss: 0.3047\n",
      "Epoch 5/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9086 - loss: 0.3259 - val_accuracy: 0.9190 - val_loss: 0.2840\n",
      "Epoch 6/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9132 - loss: 0.3056 - val_accuracy: 0.9245 - val_loss: 0.2665\n",
      "Epoch 7/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9191 - loss: 0.2865 - val_accuracy: 0.9276 - val_loss: 0.2526\n",
      "Epoch 8/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9227 - loss: 0.2685 - val_accuracy: 0.9315 - val_loss: 0.2423\n",
      "Epoch 9/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9286 - loss: 0.2536 - val_accuracy: 0.9325 - val_loss: 0.2331\n",
      "Epoch 10/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9310 - loss: 0.2418 - val_accuracy: 0.9357 - val_loss: 0.2239\n",
      "Epoch 11/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9315 - loss: 0.2377 - val_accuracy: 0.9384 - val_loss: 0.2167\n",
      "Epoch 12/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9353 - loss: 0.2262 - val_accuracy: 0.9416 - val_loss: 0.2086\n",
      "Epoch 13/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9369 - loss: 0.2205 - val_accuracy: 0.9433 - val_loss: 0.2027\n",
      "Epoch 14/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9397 - loss: 0.2124 - val_accuracy: 0.9465 - val_loss: 0.1966\n",
      "Epoch 15/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9431 - loss: 0.2019 - val_accuracy: 0.9483 - val_loss: 0.1901\n",
      "Epoch 16/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9437 - loss: 0.1975 - val_accuracy: 0.9485 - val_loss: 0.1851\n",
      "Epoch 17/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9445 - loss: 0.1917 - val_accuracy: 0.9505 - val_loss: 0.1796\n",
      "Epoch 18/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9475 - loss: 0.1846 - val_accuracy: 0.9498 - val_loss: 0.1761\n",
      "Epoch 19/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9476 - loss: 0.1811 - val_accuracy: 0.9526 - val_loss: 0.1717\n",
      "Epoch 20/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9509 - loss: 0.1707 - val_accuracy: 0.9532 - val_loss: 0.1663\n",
      "Epoch 21/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9509 - loss: 0.1698 - val_accuracy: 0.9546 - val_loss: 0.1631\n",
      "Epoch 22/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9531 - loss: 0.1641 - val_accuracy: 0.9547 - val_loss: 0.1598\n",
      "Epoch 23/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9544 - loss: 0.1594 - val_accuracy: 0.9567 - val_loss: 0.1566\n",
      "Epoch 24/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9559 - loss: 0.1551 - val_accuracy: 0.9575 - val_loss: 0.1530\n",
      "Epoch 25/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9577 - loss: 0.1468 - val_accuracy: 0.9585 - val_loss: 0.1500\n",
      "Epoch 26/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9583 - loss: 0.1466 - val_accuracy: 0.9596 - val_loss: 0.1475\n",
      "Epoch 27/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9610 - loss: 0.1377 - val_accuracy: 0.9594 - val_loss: 0.1445\n",
      "Epoch 28/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9605 - loss: 0.1399 - val_accuracy: 0.9608 - val_loss: 0.1415\n",
      "Epoch 29/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9605 - loss: 0.1363 - val_accuracy: 0.9612 - val_loss: 0.1390\n",
      "Epoch 30/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9615 - loss: 0.1333 - val_accuracy: 0.9611 - val_loss: 0.1371\n",
      "Epoch 31/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9619 - loss: 0.1335 - val_accuracy: 0.9619 - val_loss: 0.1345\n",
      "Epoch 32/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9639 - loss: 0.1240 - val_accuracy: 0.9628 - val_loss: 0.1333\n",
      "Epoch 33/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9633 - loss: 0.1269 - val_accuracy: 0.9630 - val_loss: 0.1305\n",
      "Epoch 34/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9674 - loss: 0.1177 - val_accuracy: 0.9643 - val_loss: 0.1293\n",
      "Epoch 35/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9677 - loss: 0.1165 - val_accuracy: 0.9650 - val_loss: 0.1275\n",
      "Epoch 36/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9700 - loss: 0.1098 - val_accuracy: 0.9653 - val_loss: 0.1241\n",
      "Epoch 37/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9685 - loss: 0.1122 - val_accuracy: 0.9658 - val_loss: 0.1233\n",
      "Epoch 38/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9684 - loss: 0.1096 - val_accuracy: 0.9669 - val_loss: 0.1227\n",
      "Epoch 39/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9693 - loss: 0.1105 - val_accuracy: 0.9661 - val_loss: 0.1199\n",
      "Epoch 40/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9704 - loss: 0.1059 - val_accuracy: 0.9664 - val_loss: 0.1183\n",
      "Epoch 41/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9721 - loss: 0.1007 - val_accuracy: 0.9671 - val_loss: 0.1167\n",
      "Epoch 42/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9733 - loss: 0.0984 - val_accuracy: 0.9679 - val_loss: 0.1172\n",
      "Epoch 43/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9735 - loss: 0.0973 - val_accuracy: 0.9684 - val_loss: 0.1142\n",
      "Epoch 44/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9725 - loss: 0.0976 - val_accuracy: 0.9691 - val_loss: 0.1132\n",
      "Epoch 45/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9751 - loss: 0.0925 - val_accuracy: 0.9683 - val_loss: 0.1125\n",
      "Epoch 46/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9740 - loss: 0.0932 - val_accuracy: 0.9689 - val_loss: 0.1104\n",
      "Epoch 47/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9756 - loss: 0.0879 - val_accuracy: 0.9697 - val_loss: 0.1104\n",
      "Epoch 48/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9750 - loss: 0.0920 - val_accuracy: 0.9689 - val_loss: 0.1093\n",
      "Epoch 49/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9766 - loss: 0.0865 - val_accuracy: 0.9693 - val_loss: 0.1069\n",
      "Epoch 50/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9768 - loss: 0.0868 - val_accuracy: 0.9698 - val_loss: 0.1054\n"
     ]
    }
   ],
   "source": [
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"], \n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784 * 300 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235500\n"
     ]
    }
   ],
   "source": [
    "# 1º neurona de la 1º hidden layer\n",
    "# y = a + w1*x1 + w2*x2 + .... wn*xn\n",
    "# a es el intercepto llamado bias\n",
    "# wn es cada uno de los pesos que va a ir actualizando con el backpropagation\n",
    "# n es 784\n",
    "# En la 1º hidden layer tenemos 784 pesos por cada neurona, al tener 300, tenemos un total de:\n",
    "print(784*300 + 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 784 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30100"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 100 + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1010"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * 10 + 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312.5"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "40000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9767 - loss: 0.0859 - val_accuracy: 0.9710 - val_loss: 0.1049\n",
      "Epoch 2/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9769 - loss: 0.0825 - val_accuracy: 0.9706 - val_loss: 0.1033\n",
      "Epoch 3/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9781 - loss: 0.0818 - val_accuracy: 0.9708 - val_loss: 0.1025\n",
      "Epoch 4/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9793 - loss: 0.0749 - val_accuracy: 0.9713 - val_loss: 0.1033\n",
      "Epoch 5/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9790 - loss: 0.0765 - val_accuracy: 0.9711 - val_loss: 0.1016\n",
      "Epoch 6/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9791 - loss: 0.0765 - val_accuracy: 0.9716 - val_loss: 0.1006\n",
      "Epoch 7/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9791 - loss: 0.0753 - val_accuracy: 0.9705 - val_loss: 0.1010\n",
      "Epoch 8/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9806 - loss: 0.0734 - val_accuracy: 0.9714 - val_loss: 0.0988\n",
      "Epoch 9/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9803 - loss: 0.0716 - val_accuracy: 0.9719 - val_loss: 0.0981\n",
      "Epoch 10/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9805 - loss: 0.0718 - val_accuracy: 0.9723 - val_loss: 0.0976\n",
      "Epoch 11/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9804 - loss: 0.0708 - val_accuracy: 0.9721 - val_loss: 0.0970\n",
      "Epoch 12/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9820 - loss: 0.0662 - val_accuracy: 0.9730 - val_loss: 0.0957\n",
      "Epoch 13/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9826 - loss: 0.0652 - val_accuracy: 0.9720 - val_loss: 0.0950\n",
      "Epoch 14/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9824 - loss: 0.0654 - val_accuracy: 0.9724 - val_loss: 0.0942\n",
      "Epoch 15/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9822 - loss: 0.0644 - val_accuracy: 0.9722 - val_loss: 0.0944\n",
      "Epoch 16/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9832 - loss: 0.0628 - val_accuracy: 0.9727 - val_loss: 0.0946\n",
      "Epoch 17/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9828 - loss: 0.0639 - val_accuracy: 0.9741 - val_loss: 0.0929\n",
      "Epoch 18/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9847 - loss: 0.0594 - val_accuracy: 0.9734 - val_loss: 0.0916\n",
      "Epoch 19/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9832 - loss: 0.0617 - val_accuracy: 0.9728 - val_loss: 0.0925\n",
      "Epoch 20/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9845 - loss: 0.0605 - val_accuracy: 0.9732 - val_loss: 0.0923\n",
      "Epoch 21/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9849 - loss: 0.0573 - val_accuracy: 0.9737 - val_loss: 0.0925\n",
      "Epoch 22/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9857 - loss: 0.0561 - val_accuracy: 0.9733 - val_loss: 0.0912\n",
      "Epoch 23/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9860 - loss: 0.0562 - val_accuracy: 0.9732 - val_loss: 0.0901\n",
      "Epoch 24/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9849 - loss: 0.0586 - val_accuracy: 0.9742 - val_loss: 0.0891\n",
      "Epoch 25/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9866 - loss: 0.0538 - val_accuracy: 0.9747 - val_loss: 0.0878\n",
      "Epoch 26/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9865 - loss: 0.0544 - val_accuracy: 0.9745 - val_loss: 0.0880\n",
      "Epoch 27/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9849 - loss: 0.0556 - val_accuracy: 0.9746 - val_loss: 0.0878\n",
      "Epoch 28/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9861 - loss: 0.0534 - val_accuracy: 0.9744 - val_loss: 0.0870\n",
      "Epoch 29/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9877 - loss: 0.0510 - val_accuracy: 0.9756 - val_loss: 0.0864\n",
      "Epoch 30/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9872 - loss: 0.0509 - val_accuracy: 0.9749 - val_loss: 0.0868\n",
      "Epoch 31/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9881 - loss: 0.0486 - val_accuracy: 0.9746 - val_loss: 0.0868\n",
      "Epoch 32/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9882 - loss: 0.0486 - val_accuracy: 0.9757 - val_loss: 0.0859\n",
      "Epoch 33/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9879 - loss: 0.0474 - val_accuracy: 0.9752 - val_loss: 0.0850\n",
      "Epoch 34/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9889 - loss: 0.0464 - val_accuracy: 0.9748 - val_loss: 0.0854\n",
      "Epoch 35/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9894 - loss: 0.0456 - val_accuracy: 0.9751 - val_loss: 0.0835\n",
      "Epoch 36/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9883 - loss: 0.0458 - val_accuracy: 0.9753 - val_loss: 0.0857\n",
      "Epoch 37/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9897 - loss: 0.0444 - val_accuracy: 0.9747 - val_loss: 0.0836\n",
      "Epoch 38/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9900 - loss: 0.0441 - val_accuracy: 0.9755 - val_loss: 0.0839\n",
      "Epoch 39/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9888 - loss: 0.0453 - val_accuracy: 0.9756 - val_loss: 0.0837\n",
      "Epoch 40/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9903 - loss: 0.0402 - val_accuracy: 0.9754 - val_loss: 0.0839\n",
      "Epoch 41/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9903 - loss: 0.0430 - val_accuracy: 0.9746 - val_loss: 0.0825\n",
      "Epoch 42/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9900 - loss: 0.0420 - val_accuracy: 0.9754 - val_loss: 0.0828\n",
      "Epoch 43/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9906 - loss: 0.0412 - val_accuracy: 0.9756 - val_loss: 0.0824\n",
      "Epoch 44/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9900 - loss: 0.0402 - val_accuracy: 0.9751 - val_loss: 0.0820\n",
      "Epoch 45/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9908 - loss: 0.0390 - val_accuracy: 0.9755 - val_loss: 0.0824\n",
      "Epoch 46/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9907 - loss: 0.0393 - val_accuracy: 0.9752 - val_loss: 0.0819\n",
      "Epoch 47/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9906 - loss: 0.0395 - val_accuracy: 0.9758 - val_loss: 0.0812\n",
      "Epoch 48/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9910 - loss: 0.0386 - val_accuracy: 0.9759 - val_loss: 0.0816\n",
      "Epoch 49/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9917 - loss: 0.0366 - val_accuracy: 0.9766 - val_loss: 0.0820\n",
      "Epoch 50/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9921 - loss: 0.0357 - val_accuracy: 0.9755 - val_loss: 0.0812\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9915 - loss: 0.0368 - val_accuracy: 0.9756 - val_loss: 0.0823\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9918 - loss: 0.0360 - val_accuracy: 0.9749 - val_loss: 0.0835\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9920 - loss: 0.0351 - val_accuracy: 0.9762 - val_loss: 0.0814\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9922 - loss: 0.0350 - val_accuracy: 0.9766 - val_loss: 0.0821\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9920 - loss: 0.0337 - val_accuracy: 0.9757 - val_loss: 0.0815\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9932 - loss: 0.0307 - val_accuracy: 0.9762 - val_loss: 0.0791\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9934 - loss: 0.0307 - val_accuracy: 0.9768 - val_loss: 0.0786\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9939 - loss: 0.0299 - val_accuracy: 0.9775 - val_loss: 0.0816\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9934 - loss: 0.0305 - val_accuracy: 0.9767 - val_loss: 0.0780\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9944 - loss: 0.0279 - val_accuracy: 0.9766 - val_loss: 0.0780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1bf01333e50>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': [0.9770399928092957, 0.9775199890136719, 0.9778000116348267, 0.9783200025558472, 0.9785400032997131, 0.9791600108146667, 0.9794800281524658, 0.9798799753189087, 0.9804400205612183, 0.9807199835777283, 0.980679988861084, 0.9814000129699707, 0.9820399880409241, 0.9823200106620789, 0.982200026512146, 0.9828199744224548, 0.9833400249481201, 0.9833800196647644, 0.9837999939918518, 0.9841399788856506, 0.9842000007629395, 0.9847000241279602, 0.9851999878883362, 0.9853799939155579, 0.9858199954032898, 0.9862599968910217, 0.9864199757575989, 0.9868000149726868, 0.9872599840164185, 0.9869599938392639, 0.9874399900436401, 0.9879000186920166, 0.987779974937439, 0.9882599711418152, 0.9885600209236145, 0.9886999726295471, 0.9891800284385681, 0.9895200133323669, 0.9894599914550781, 0.9894800186157227, 0.9898800253868103, 0.9898999929428101, 0.9901800155639648, 0.9902799725532532, 0.9904999732971191, 0.9909600019454956, 0.9909999966621399, 0.9911999702453613, 0.9914600253105164, 0.9914799928665161], 'loss': [0.08415493369102478, 0.08242124319076538, 0.08103828877210617, 0.07936591655015945, 0.07806670665740967, 0.07655835151672363, 0.07503242045640945, 0.07397298514842987, 0.07255658507347107, 0.07123678922653198, 0.06984958797693253, 0.06865303963422775, 0.06748966127634048, 0.06639587134122849, 0.06509533524513245, 0.06403981894254684, 0.06289131194353104, 0.06180150806903839, 0.06069562956690788, 0.05972994491457939, 0.05877891555428505, 0.057757262140512466, 0.056676365435123444, 0.05582505464553833, 0.05504122003912926, 0.054007638245821, 0.05308828130364418, 0.052253007888793945, 0.05134401470422745, 0.05071966350078583, 0.049906786531209946, 0.0488908626139164, 0.0483221597969532, 0.047583285719156265, 0.046748194843530655, 0.04600980505347252, 0.04521933197975159, 0.04449351504445076, 0.04393230378627777, 0.043120186775922775, 0.042504195123910904, 0.04184001311659813, 0.041199468076229095, 0.040571797639131546, 0.03991595655679703, 0.039270829409360886, 0.038649722933769226, 0.03813806548714638, 0.03757937252521515, 0.037049513310194016], 'val_accuracy': [0.9710000157356262, 0.9706000089645386, 0.97079998254776, 0.9713000059127808, 0.9710999727249146, 0.9715999960899353, 0.9704999923706055, 0.9714000225067139, 0.9718999862670898, 0.9722999930381775, 0.972100019454956, 0.9729999899864197, 0.972000002861023, 0.9724000096321106, 0.9721999764442444, 0.9726999998092651, 0.9740999937057495, 0.9733999967575073, 0.9728000164031982, 0.9732000231742859, 0.9736999869346619, 0.9732999801635742, 0.9732000231742859, 0.9742000102996826, 0.9746999740600586, 0.9745000004768372, 0.9746000170707703, 0.974399983882904, 0.975600004196167, 0.9749000072479248, 0.9746000170707703, 0.9757000207901001, 0.9751999974250793, 0.9747999906539917, 0.9750999808311462, 0.9753000140190125, 0.9746999740600586, 0.9754999876022339, 0.975600004196167, 0.9753999710083008, 0.9746000170707703, 0.9753999710083008, 0.975600004196167, 0.9750999808311462, 0.9754999876022339, 0.9751999974250793, 0.9757999777793884, 0.9758999943733215, 0.9765999913215637, 0.9754999876022339], 'val_loss': [0.104918472468853, 0.10328297317028046, 0.10248047858476639, 0.10332690179347992, 0.10159711539745331, 0.10056137293577194, 0.10095753520727158, 0.09878633916378021, 0.09812352061271667, 0.0975944846868515, 0.09700754284858704, 0.09571520984172821, 0.09503552317619324, 0.09416265040636063, 0.09440333396196365, 0.09462817758321762, 0.09289450198411942, 0.09161680191755295, 0.09248178452253342, 0.0922902300953865, 0.09249036759138107, 0.09121456742286682, 0.09010197967290878, 0.08912122249603271, 0.0877964198589325, 0.0879758670926094, 0.0878404751420021, 0.08696051687002182, 0.08643383532762527, 0.08677450567483902, 0.08682088553905487, 0.08589434623718262, 0.08498258888721466, 0.08541237562894821, 0.08350740373134613, 0.08571804314851761, 0.08363169431686401, 0.08392486721277237, 0.08368631452322006, 0.08385179191827774, 0.0825420394539833, 0.08284512907266617, 0.0824432224035263, 0.08201931416988373, 0.08239765465259552, 0.08188917487859726, 0.08122711628675461, 0.08160573244094849, 0.08204767107963562, 0.08119861781597137]}\n"
     ]
    }
   ],
   "source": [
    "# print(history.params)\n",
    "# print(history.epoch)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.9770399928092957,\n",
       "  0.9775199890136719,\n",
       "  0.9778000116348267,\n",
       "  0.9783200025558472,\n",
       "  0.9785400032997131,\n",
       "  0.9791600108146667,\n",
       "  0.9794800281524658,\n",
       "  0.9798799753189087,\n",
       "  0.9804400205612183,\n",
       "  0.9807199835777283,\n",
       "  0.980679988861084,\n",
       "  0.9814000129699707,\n",
       "  0.9820399880409241,\n",
       "  0.9823200106620789,\n",
       "  0.982200026512146,\n",
       "  0.9828199744224548,\n",
       "  0.9833400249481201,\n",
       "  0.9833800196647644,\n",
       "  0.9837999939918518,\n",
       "  0.9841399788856506,\n",
       "  0.9842000007629395,\n",
       "  0.9847000241279602,\n",
       "  0.9851999878883362,\n",
       "  0.9853799939155579,\n",
       "  0.9858199954032898,\n",
       "  0.9862599968910217,\n",
       "  0.9864199757575989,\n",
       "  0.9868000149726868,\n",
       "  0.9872599840164185,\n",
       "  0.9869599938392639,\n",
       "  0.9874399900436401,\n",
       "  0.9879000186920166,\n",
       "  0.987779974937439,\n",
       "  0.9882599711418152,\n",
       "  0.9885600209236145,\n",
       "  0.9886999726295471,\n",
       "  0.9891800284385681,\n",
       "  0.9895200133323669,\n",
       "  0.9894599914550781,\n",
       "  0.9894800186157227,\n",
       "  0.9898800253868103,\n",
       "  0.9898999929428101,\n",
       "  0.9901800155639648,\n",
       "  0.9902799725532532,\n",
       "  0.9904999732971191,\n",
       "  0.9909600019454956,\n",
       "  0.9909999966621399,\n",
       "  0.9911999702453613,\n",
       "  0.9914600253105164,\n",
       "  0.9914799928665161],\n",
       " 'loss': [0.08415493369102478,\n",
       "  0.08242124319076538,\n",
       "  0.08103828877210617,\n",
       "  0.07936591655015945,\n",
       "  0.07806670665740967,\n",
       "  0.07655835151672363,\n",
       "  0.07503242045640945,\n",
       "  0.07397298514842987,\n",
       "  0.07255658507347107,\n",
       "  0.07123678922653198,\n",
       "  0.06984958797693253,\n",
       "  0.06865303963422775,\n",
       "  0.06748966127634048,\n",
       "  0.06639587134122849,\n",
       "  0.06509533524513245,\n",
       "  0.06403981894254684,\n",
       "  0.06289131194353104,\n",
       "  0.06180150806903839,\n",
       "  0.06069562956690788,\n",
       "  0.05972994491457939,\n",
       "  0.05877891555428505,\n",
       "  0.057757262140512466,\n",
       "  0.056676365435123444,\n",
       "  0.05582505464553833,\n",
       "  0.05504122003912926,\n",
       "  0.054007638245821,\n",
       "  0.05308828130364418,\n",
       "  0.052253007888793945,\n",
       "  0.05134401470422745,\n",
       "  0.05071966350078583,\n",
       "  0.049906786531209946,\n",
       "  0.0488908626139164,\n",
       "  0.0483221597969532,\n",
       "  0.047583285719156265,\n",
       "  0.046748194843530655,\n",
       "  0.04600980505347252,\n",
       "  0.04521933197975159,\n",
       "  0.04449351504445076,\n",
       "  0.04393230378627777,\n",
       "  0.043120186775922775,\n",
       "  0.042504195123910904,\n",
       "  0.04184001311659813,\n",
       "  0.041199468076229095,\n",
       "  0.040571797639131546,\n",
       "  0.03991595655679703,\n",
       "  0.039270829409360886,\n",
       "  0.038649722933769226,\n",
       "  0.03813806548714638,\n",
       "  0.03757937252521515,\n",
       "  0.037049513310194016],\n",
       " 'val_accuracy': [0.9710000157356262,\n",
       "  0.9706000089645386,\n",
       "  0.97079998254776,\n",
       "  0.9713000059127808,\n",
       "  0.9710999727249146,\n",
       "  0.9715999960899353,\n",
       "  0.9704999923706055,\n",
       "  0.9714000225067139,\n",
       "  0.9718999862670898,\n",
       "  0.9722999930381775,\n",
       "  0.972100019454956,\n",
       "  0.9729999899864197,\n",
       "  0.972000002861023,\n",
       "  0.9724000096321106,\n",
       "  0.9721999764442444,\n",
       "  0.9726999998092651,\n",
       "  0.9740999937057495,\n",
       "  0.9733999967575073,\n",
       "  0.9728000164031982,\n",
       "  0.9732000231742859,\n",
       "  0.9736999869346619,\n",
       "  0.9732999801635742,\n",
       "  0.9732000231742859,\n",
       "  0.9742000102996826,\n",
       "  0.9746999740600586,\n",
       "  0.9745000004768372,\n",
       "  0.9746000170707703,\n",
       "  0.974399983882904,\n",
       "  0.975600004196167,\n",
       "  0.9749000072479248,\n",
       "  0.9746000170707703,\n",
       "  0.9757000207901001,\n",
       "  0.9751999974250793,\n",
       "  0.9747999906539917,\n",
       "  0.9750999808311462,\n",
       "  0.9753000140190125,\n",
       "  0.9746999740600586,\n",
       "  0.9754999876022339,\n",
       "  0.975600004196167,\n",
       "  0.9753999710083008,\n",
       "  0.9746000170707703,\n",
       "  0.9753999710083008,\n",
       "  0.975600004196167,\n",
       "  0.9750999808311462,\n",
       "  0.9754999876022339,\n",
       "  0.9751999974250793,\n",
       "  0.9757999777793884,\n",
       "  0.9758999943733215,\n",
       "  0.9765999913215637,\n",
       "  0.9754999876022339],\n",
       " 'val_loss': [0.104918472468853,\n",
       "  0.10328297317028046,\n",
       "  0.10248047858476639,\n",
       "  0.10332690179347992,\n",
       "  0.10159711539745331,\n",
       "  0.10056137293577194,\n",
       "  0.10095753520727158,\n",
       "  0.09878633916378021,\n",
       "  0.09812352061271667,\n",
       "  0.0975944846868515,\n",
       "  0.09700754284858704,\n",
       "  0.09571520984172821,\n",
       "  0.09503552317619324,\n",
       "  0.09416265040636063,\n",
       "  0.09440333396196365,\n",
       "  0.09462817758321762,\n",
       "  0.09289450198411942,\n",
       "  0.09161680191755295,\n",
       "  0.09248178452253342,\n",
       "  0.0922902300953865,\n",
       "  0.09249036759138107,\n",
       "  0.09121456742286682,\n",
       "  0.09010197967290878,\n",
       "  0.08912122249603271,\n",
       "  0.0877964198589325,\n",
       "  0.0879758670926094,\n",
       "  0.0878404751420021,\n",
       "  0.08696051687002182,\n",
       "  0.08643383532762527,\n",
       "  0.08677450567483902,\n",
       "  0.08682088553905487,\n",
       "  0.08589434623718262,\n",
       "  0.08498258888721466,\n",
       "  0.08541237562894821,\n",
       "  0.08350740373134613,\n",
       "  0.08571804314851761,\n",
       "  0.08363169431686401,\n",
       "  0.08392486721277237,\n",
       "  0.08368631452322006,\n",
       "  0.08385179191827774,\n",
       "  0.0825420394539833,\n",
       "  0.08284512907266617,\n",
       "  0.0824432224035263,\n",
       "  0.08201931416988373,\n",
       "  0.08239765465259552,\n",
       "  0.08188917487859726,\n",
       "  0.08122711628675461,\n",
       "  0.08160573244094849,\n",
       "  0.08204767107963562,\n",
       "  0.08119861781597137]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.97704</td>\n",
       "      <td>0.084155</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.104918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.97752</td>\n",
       "      <td>0.082421</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.103283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.97780</td>\n",
       "      <td>0.081038</td>\n",
       "      <td>0.9708</td>\n",
       "      <td>0.102480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.97832</td>\n",
       "      <td>0.079366</td>\n",
       "      <td>0.9713</td>\n",
       "      <td>0.103327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.97854</td>\n",
       "      <td>0.078067</td>\n",
       "      <td>0.9711</td>\n",
       "      <td>0.101597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.97916</td>\n",
       "      <td>0.076558</td>\n",
       "      <td>0.9716</td>\n",
       "      <td>0.100561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.97948</td>\n",
       "      <td>0.075032</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.100958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.97988</td>\n",
       "      <td>0.073973</td>\n",
       "      <td>0.9714</td>\n",
       "      <td>0.098786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.98044</td>\n",
       "      <td>0.072557</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.098124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.98072</td>\n",
       "      <td>0.071237</td>\n",
       "      <td>0.9723</td>\n",
       "      <td>0.097594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.98068</td>\n",
       "      <td>0.069850</td>\n",
       "      <td>0.9721</td>\n",
       "      <td>0.097008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.98140</td>\n",
       "      <td>0.068653</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.095715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.98204</td>\n",
       "      <td>0.067490</td>\n",
       "      <td>0.9720</td>\n",
       "      <td>0.095036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.98232</td>\n",
       "      <td>0.066396</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.094163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.98220</td>\n",
       "      <td>0.065095</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.094403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.98282</td>\n",
       "      <td>0.064040</td>\n",
       "      <td>0.9727</td>\n",
       "      <td>0.094628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.98334</td>\n",
       "      <td>0.062891</td>\n",
       "      <td>0.9741</td>\n",
       "      <td>0.092895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.98338</td>\n",
       "      <td>0.061802</td>\n",
       "      <td>0.9734</td>\n",
       "      <td>0.091617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.98380</td>\n",
       "      <td>0.060696</td>\n",
       "      <td>0.9728</td>\n",
       "      <td>0.092482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.98414</td>\n",
       "      <td>0.059730</td>\n",
       "      <td>0.9732</td>\n",
       "      <td>0.092290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.98420</td>\n",
       "      <td>0.058779</td>\n",
       "      <td>0.9737</td>\n",
       "      <td>0.092490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.98470</td>\n",
       "      <td>0.057757</td>\n",
       "      <td>0.9733</td>\n",
       "      <td>0.091215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.98520</td>\n",
       "      <td>0.056676</td>\n",
       "      <td>0.9732</td>\n",
       "      <td>0.090102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.98538</td>\n",
       "      <td>0.055825</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>0.089121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.98582</td>\n",
       "      <td>0.055041</td>\n",
       "      <td>0.9747</td>\n",
       "      <td>0.087796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.98626</td>\n",
       "      <td>0.054008</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>0.087976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.98642</td>\n",
       "      <td>0.053088</td>\n",
       "      <td>0.9746</td>\n",
       "      <td>0.087840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.98680</td>\n",
       "      <td>0.052253</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.086961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.98726</td>\n",
       "      <td>0.051344</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.086434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.98696</td>\n",
       "      <td>0.050720</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>0.086775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.98744</td>\n",
       "      <td>0.049907</td>\n",
       "      <td>0.9746</td>\n",
       "      <td>0.086821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.98790</td>\n",
       "      <td>0.048891</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.085894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.98778</td>\n",
       "      <td>0.048322</td>\n",
       "      <td>0.9752</td>\n",
       "      <td>0.084983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.98826</td>\n",
       "      <td>0.047583</td>\n",
       "      <td>0.9748</td>\n",
       "      <td>0.085412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.98856</td>\n",
       "      <td>0.046748</td>\n",
       "      <td>0.9751</td>\n",
       "      <td>0.083507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.98870</td>\n",
       "      <td>0.046010</td>\n",
       "      <td>0.9753</td>\n",
       "      <td>0.085718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.98918</td>\n",
       "      <td>0.045219</td>\n",
       "      <td>0.9747</td>\n",
       "      <td>0.083632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.98952</td>\n",
       "      <td>0.044494</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.083925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.98946</td>\n",
       "      <td>0.043932</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.083686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.98948</td>\n",
       "      <td>0.043120</td>\n",
       "      <td>0.9754</td>\n",
       "      <td>0.083852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.98988</td>\n",
       "      <td>0.042504</td>\n",
       "      <td>0.9746</td>\n",
       "      <td>0.082542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.98990</td>\n",
       "      <td>0.041840</td>\n",
       "      <td>0.9754</td>\n",
       "      <td>0.082845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.99018</td>\n",
       "      <td>0.041199</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.082443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.99028</td>\n",
       "      <td>0.040572</td>\n",
       "      <td>0.9751</td>\n",
       "      <td>0.082019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.99050</td>\n",
       "      <td>0.039916</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.082398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.99096</td>\n",
       "      <td>0.039271</td>\n",
       "      <td>0.9752</td>\n",
       "      <td>0.081889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.99100</td>\n",
       "      <td>0.038650</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.081227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.99120</td>\n",
       "      <td>0.038138</td>\n",
       "      <td>0.9759</td>\n",
       "      <td>0.081606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.99146</td>\n",
       "      <td>0.037579</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>0.082048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.99148</td>\n",
       "      <td>0.037050</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.081199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy      loss  val_accuracy  val_loss\n",
       "0    0.97704  0.084155        0.9710  0.104918\n",
       "1    0.97752  0.082421        0.9706  0.103283\n",
       "2    0.97780  0.081038        0.9708  0.102480\n",
       "3    0.97832  0.079366        0.9713  0.103327\n",
       "4    0.97854  0.078067        0.9711  0.101597\n",
       "5    0.97916  0.076558        0.9716  0.100561\n",
       "6    0.97948  0.075032        0.9705  0.100958\n",
       "7    0.97988  0.073973        0.9714  0.098786\n",
       "8    0.98044  0.072557        0.9719  0.098124\n",
       "9    0.98072  0.071237        0.9723  0.097594\n",
       "10   0.98068  0.069850        0.9721  0.097008\n",
       "11   0.98140  0.068653        0.9730  0.095715\n",
       "12   0.98204  0.067490        0.9720  0.095036\n",
       "13   0.98232  0.066396        0.9724  0.094163\n",
       "14   0.98220  0.065095        0.9722  0.094403\n",
       "15   0.98282  0.064040        0.9727  0.094628\n",
       "16   0.98334  0.062891        0.9741  0.092895\n",
       "17   0.98338  0.061802        0.9734  0.091617\n",
       "18   0.98380  0.060696        0.9728  0.092482\n",
       "19   0.98414  0.059730        0.9732  0.092290\n",
       "20   0.98420  0.058779        0.9737  0.092490\n",
       "21   0.98470  0.057757        0.9733  0.091215\n",
       "22   0.98520  0.056676        0.9732  0.090102\n",
       "23   0.98538  0.055825        0.9742  0.089121\n",
       "24   0.98582  0.055041        0.9747  0.087796\n",
       "25   0.98626  0.054008        0.9745  0.087976\n",
       "26   0.98642  0.053088        0.9746  0.087840\n",
       "27   0.98680  0.052253        0.9744  0.086961\n",
       "28   0.98726  0.051344        0.9756  0.086434\n",
       "29   0.98696  0.050720        0.9749  0.086775\n",
       "30   0.98744  0.049907        0.9746  0.086821\n",
       "31   0.98790  0.048891        0.9757  0.085894\n",
       "32   0.98778  0.048322        0.9752  0.084983\n",
       "33   0.98826  0.047583        0.9748  0.085412\n",
       "34   0.98856  0.046748        0.9751  0.083507\n",
       "35   0.98870  0.046010        0.9753  0.085718\n",
       "36   0.98918  0.045219        0.9747  0.083632\n",
       "37   0.98952  0.044494        0.9755  0.083925\n",
       "38   0.98946  0.043932        0.9756  0.083686\n",
       "39   0.98948  0.043120        0.9754  0.083852\n",
       "40   0.98988  0.042504        0.9746  0.082542\n",
       "41   0.98990  0.041840        0.9754  0.082845\n",
       "42   0.99018  0.041199        0.9756  0.082443\n",
       "43   0.99028  0.040572        0.9751  0.082019\n",
       "44   0.99050  0.039916        0.9755  0.082398\n",
       "45   0.99096  0.039271        0.9752  0.081889\n",
       "46   0.99100  0.038650        0.9758  0.081227\n",
       "47   0.99120  0.038138        0.9759  0.081606\n",
       "48   0.99146  0.037579        0.9766  0.082048\n",
       "49   0.99148  0.037050        0.9755  0.081199"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9729 - loss: 0.0868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego Nuñez\\AppData\\Local\\Temp\\ipykernel_5528\\1468152043.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.002, 0.   , 0.   , 0.   , 0.998, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1])\n",
    "print(predictions.shape)\n",
    "np.round(predictions,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.7749625e-06, 1.2438736e-07, 2.5430107e-05, 1.5541624e-03,\n",
       "        1.3422910e-08, 1.6378835e-06, 1.9454371e-12, 9.9837226e-01,\n",
       "        1.2951803e-05, 3.0661467e-05]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(7)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312.5"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[0]/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego Nuñez\\AppData\\Local\\Temp\\ipykernel_5528\\1084033691.py:1: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  plt.imshow(X_test[2].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[2].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  70,  833,    0,    0,    0,    0,   77,    0,    0,    0],\n",
       "       [   0, 1135,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0, 1030,    0,    0,    0,    0,    2,    0,    0,    0],\n",
       "       [   0, 1010,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,  980,    0,    0,    0,    0,    2,    0,    0,    0],\n",
       "       [   0,  892,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,  878,    0,    0,    0,    0,   80,    0,    0,    0],\n",
       "       [   0,  990,    0,    0,    0,    0,    0,   38,    0,    0],\n",
       "       [   0,  974,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0, 1008,    0,    0,    0,    0,    1,    0,    0,    0]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "confusion_matrix(y_test, model.predict(X_test).argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98       980\n",
      "         1.0       0.98      0.99      0.99      1135\n",
      "         2.0       0.97      0.97      0.97      1032\n",
      "         3.0       0.96      0.98      0.97      1010\n",
      "         4.0       0.98      0.97      0.97       982\n",
      "         5.0       0.98      0.97      0.97       892\n",
      "         6.0       0.98      0.97      0.97       958\n",
      "         7.0       0.98      0.97      0.97      1028\n",
      "         8.0       0.96      0.97      0.96       974\n",
      "         9.0       0.97      0.96      0.96      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(X_test).argmax(axis=1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.8125"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11610/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Diego Nuñez\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8201 - val_loss: 0.5299\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5177 - val_loss: 0.4643\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4619 - val_loss: 0.4324\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4295 - val_loss: 0.4210\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4291 - val_loss: 0.4164\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4260 - val_loss: 0.3982\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4150 - val_loss: 0.3858\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3936 - val_loss: 0.3858\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3836 - val_loss: 0.3767\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4110 - val_loss: 0.3717\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3880 - val_loss: 0.3682\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3687 - val_loss: 0.3685\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3938 - val_loss: 0.3903\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4130 - val_loss: 0.3802\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3789 - val_loss: 0.3614\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3733 - val_loss: 0.3649\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3808 - val_loss: 0.3598\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3710 - val_loss: 0.3565\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3769 - val_loss: 0.3609\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3784 - val_loss: 0.3512\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = \"sgd\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*30 + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m270\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">303</span> (1.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m303\u001b[0m (1.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301</span> (1.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m301\u001b[0m (1.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3689\n",
      "0.3622754216194153\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.3760054],\n",
       "       [1.2083163],\n",
       "       [2.072228 ],\n",
       "       [0.6865401],\n",
       "       [1.1529279]], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "numpy() is only available when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[118]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m checkpoint_cb = keras.callbacks.ModelCheckpoint(\u001b[33m\"\u001b[39m\u001b[33mcallback_model.h5\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                   \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Diego Nuñez\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Diego Nuñez\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:171\u001b[39m, in \u001b[36mconvert_to_numpy\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, tf.RaggedTensor):\n\u001b[32m    170\u001b[39m     x = x.to_tensor()\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.array(x)\n",
      "\u001b[31mNotImplementedError\u001b[39m: numpy() is only available when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=30,\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_valid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m early_stopping_cb = keras.callbacks.EarlyStopping(patience=\u001b[32m3\u001b[39m)\n\u001b[32m      2\u001b[39m history = model.fit(X_train,\n\u001b[32m      3\u001b[39m                    y_train,\n\u001b[32m      4\u001b[39m                    epochs=\u001b[32m50\u001b[39m,\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m                    validation_data = (\u001b[43mX_valid\u001b[49m, y_valid),\n\u001b[32m      6\u001b[39m                    callbacks = [early_stopping_cb, checkpoint_cb])\n",
      "\u001b[31mNameError\u001b[39m: name 'X_valid' is not defined"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3)\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=50,\n",
    "                   validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb, checkpoint_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
