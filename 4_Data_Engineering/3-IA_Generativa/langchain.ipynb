{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bbfb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5953ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13c8e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a3fc5a",
   "metadata": {},
   "source": [
    "messages es una lista de mensajes de conversación que se envían al modelo.\n",
    "\n",
    "LangChain usa un formato estructurado de chat, no solo texto plano, para que el modelo entienda:\n",
    "\n",
    "- Quién habla\n",
    "\n",
    "- Con qué intención\n",
    "\n",
    "- En qué orden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d9ee6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Tarta de Queso: Un Clásico Delicioso**\n",
      "\n",
      "¡Claro que sí! Me alegra que quieras aprender a hacer una deliciosa tarta de queso. Aquí te presento una receta básica y fácil de seguir.\n",
      "\n",
      "**Ingredientes:**\n",
      "\n",
      "* **Para la base:**\n",
      " + 200g de galletas de chocolate o vainilla (aproximadamente 1 taza y media)\n",
      " + 100g de mantequilla derretida (aproximadamente 1/2 taza)\n",
      "* **Para el relleno:**\n",
      " + 500g de queso crema (aproximadamente 2 tazas y media)\n",
      " + 200g de azúcar (aproximadamente 1 taza)\n",
      " + 4 huevos grandes\n",
      " + 1 cucharadita de extracto de vainilla\n",
      " + 200g de crema agria (aproximadamente 1 taza)\n",
      "\n",
      "**Instrucciones:**\n",
      "\n",
      "1. **Preparar la base:**\n",
      " * Tritura las galletas en un procesador de alimentos hasta que queden finamente molidas.\n",
      " * Mezcla las galletas molidas con la mantequilla derretida hasta que estén bien combinadas.\n",
      " * Presiona la mezcla en el fondo de un molde para tartas de 24 cm de diámetro.\n",
      " * Hornea la base en un horno precalentado a 180°C durante 10 minutos. Deja enfriar completamente.\n",
      "2. **Preparar el relleno:**\n",
      " * Bate el queso crema en un tazón grande hasta que esté suave.\n",
      " * Agrega el azúcar y bate hasta que esté bien combinado.\n",
      " * Agrega los huevos uno a uno, batiendo bien después de cada adición.\n",
      " * Agrega el extracto de vainilla y la crema agria, y bate hasta que estén bien combinados.\n",
      "3. **Armar y hornear la tarta:**\n",
      " * Vierte el relleno sobre la base horneada.\n",
      " * Hornea la tarta en un horno precalentado a 160°C durante 45-50 minutos, o hasta que esté firme y ligeramente dorada.\n",
      " * Deja enfriar la tarta en el horno con la puerta entreabierta durante 1 hora.\n",
      " * Retira la tarta del horno y deja enfriar completamente en una rejilla.\n",
      "\n",
      "**Consejos y Variaciones:**\n",
      "\n",
      "* Asegúrate de que el queso crema esté a temperatura ambiente antes de empezar a batir.\n",
      "* Puedes agregar diferentes sabores a la tarta, como frutas frescas o chocolate rallado.\n",
      "* Si deseas una tarta más densa, puedes agregar un poco más de queso crema o reducir la cantidad de crema agria.\n",
      "\n",
      "**Conclusión:**\n",
      "\n",
      "¡Eso es todo! Con esta receta, podrás crear una deliciosa tarta de queso que seguro será un éxito en cualquier reunión o celebración. Recuerda que la práctica hace la perfección, así que no tengas miedo de experimentar y ajustar la receta a tus gustos. ¡Disfruta de tu tarta de queso!\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGroq(\n",
    "    model=\"meta-llama/llama-4-maverick-17b-128e-instruct\",\n",
    "    temperature=0.2,\n",
    "    #timeout=30,               \n",
    "    #max_retries=2,            \n",
    "    groq_api_key=api_key\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=\"Quiero que me muestres como hacer una tarta de queso\")\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a973facf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Claro! Un Random Forest es un algoritmo de aprendizaje automático muy útil para problemas de clasificación y regresión. Aquí te guiaré a través de los pasos para implementarlo.\n",
      "\n",
      "**Paso 1: Preparación de los datos**\n",
      "\n",
      "Antes de empezar, asegúrate de que tengas un conjunto de datos listo para trabajar. ¿Cuál es el problema que estás tratando de resolver con tu modelo? ¿Es un problema de clasificación o regresión? ¿Cuál es la variable objetivo que deseas predecir?\n",
      "\n",
      "**Paso 2: Selección de la biblioteca**\n",
      "\n",
      "Vamos a utilizar la biblioteca Scikit-learn en Python, que es una de las más populares para el aprendizaje automático. ¿Estás familiarizado con esta biblioteca? ¿Has utilizado alguna vez la clase `RandomForestClassifier` o `RandomForestRegressor`?\n",
      "\n",
      "**Paso 3: Configuración del modelo**\n",
      "\n",
      "Un Random Forest tiene varios hiperparámetros que debes configurar. Algunos de los más importantes son:\n",
      "\n",
      "* `n_estimators`: el número de árboles de decisión que se utilizarán en el bosque.\n",
      "* `max_depth`: la profundidad máxima de cada árbol de decisión.\n",
      "* `min_samples_split`: el número mínimo de muestras necesarias para dividir un nodo.\n",
      "\n",
      "¿Qué valores crees que podrían ser adecuados para estos hiperparámetros en tu problema?\n",
      "\n",
      "**Paso 4: Entrenamiento del modelo**\n",
      "\n",
      "Una vez que hayas configurado el modelo, debes entrenarlo con tus datos. ¿Cómo crees que debes dividir tus datos para entrenar y evaluar el modelo?\n",
      "\n",
      "**Paso 5: Evaluación del modelo**\n",
      "\n",
      "Después de entrenar el modelo, debes evaluar su rendimiento. ¿Qué métricas crees que debes utilizar para evaluar el rendimiento de tu modelo? ¿Por qué?\n",
      "\n",
      "Aquí te dejo un ejemplo de código para que puedas empezar:\n",
      "```python\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.datasets import load_iris\n",
      "\n",
      "# Carga el conjunto de datos iris\n",
      "iris = load_iris()\n",
      "X = iris.data\n",
      "y = iris.target\n",
      "\n",
      "# Divide los datos en entrenamiento y prueba\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "# Crea un objeto RandomForestClassifier\n",
      "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
      "\n",
      "# Entrena el modelo\n",
      "rf.fit(X_train, y_train)\n",
      "```\n",
      "¿Qué sucede si cambias el valor de `n_estimators` a 50 o 200? ¿Cómo afecta esto al rendimiento del modelo?\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=(\n",
    "            \"\"\"Eres un profesor de un bootcamp de ciencia de datos. quiero que me ayudes\n",
    "            en problemas técnicos, tanto en conceptos como en programación. Quiero que siempre que me\n",
    "            respondas sea ayudándome. No dandome la solución\"\"\"\n",
    "        )\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"muestrame como hacer un random forest\"\n",
    "    )\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac031e",
   "metadata": {},
   "source": [
    "## Memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "214ae6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd0bbbd",
   "metadata": {},
   "source": [
    "### Configuración del Modelo\n",
    "Asegúrate de usar un modelo válido de Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b5fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model=\"meta-llama/llama-4-maverick-17b-128e-instruct\", \n",
    "    temperature=0.3,\n",
    "    groq_api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5126b3",
   "metadata": {},
   "source": [
    "### Definición del Prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "212be4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Eres un profesor de un bootcamp de ciencia de datos. quiero que me ayudes\n",
    "            en problemas técnicos, tanto en conceptos como en programación. Quiero que siempre que me\n",
    "            respondas sea ayudándome. No dandome la solución\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af65b53",
   "metadata": {},
   "source": [
    "### Creación de la Cadena usando LCEL (LangChain Expression Language).\n",
    "Esto une el prompt con el modelo de forma declarativa, usando el operador pipe '|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2994bf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e22b4",
   "metadata": {},
   "source": [
    "### Gestión de Memoria.\n",
    "En lugar de ConversationBufferMemory, usamos un almacén de mensajes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3aa1575",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_historial = ChatMessageHistory()\n",
    "\n",
    "cadena_historial = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda session_id: chat_historial,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b29d69",
   "metadata": {},
   "source": [
    "### Bucle de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "57e14557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aula Virtual de Data Science (escribe 'salir' para terminar)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Aula Virtual de Data Science (escribe 'salir' para terminar)\\n\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Alumno: \")\n",
    "    if user_input.lower() in [\"salir\", \"exit\"]:\n",
    "        break\n",
    "    \n",
    "    # Invocamos la cadena pasando un config con el session_id\n",
    "    response = cadena_historial.invoke(\n",
    "        {\"input\": user_input},\n",
    "        config={\"configurable\": {\"session_id\": \"bootcamp_01\"}}\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nProfe: {response.content}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
